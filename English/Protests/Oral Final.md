## Hook
Over the past decade we have seen the historic rise of AI technology from simple chatbots, to image recognition, and now seemingly a goldmine of endless capabilities, yet our perception of this modern marvel has been skewed by popular culture and more than ever the misunderstanding of artificial intelligence, its capabilities and in turn its dangers is at an all time high among Australians. The craze we've witnessed surrounding this magical technology has been fuelled by sensationalised depictions in media and the lack of comprehensive education on the subject, allowing consumers to be fed misinformation and form a widespread mistrust across the country. As I would consider myself, a well informed student on the subject, I aim to shed light on this complex issue and dispel public misunderstanding for you, the consumer, to reconcile fears of the technology, understand its limitations and be informed of its real dangers.

## Public Misunderstanding
Misconceptions of artificial intelligence and its capabilities as a result of pop-culture influences has led to great disparity in the average Australians understanding of the technology and how it effect them. An extremely recent example of this misinformation being promoted to Australian consumers is an article published by seven news Australia on the eighth of June covering a recent cyber attack on the department of transports 'Myki' system sparked widespread fears of AI misuse among viewers. This came as the popular news outlet interviewed a quote on quote "cyber security expert", Shameela Gonzalez, on the attack in which fraudsters had registered the codes of victims Myki cards online to withdraw their balance. Shameela stated this attack was conducted the 'superpower of AI' to 'identify unregistered cards'.

Although like most of you I consider myself to be no 'cyber security expert', I was however able to identify the methodology used in this cyber attack with a quick look at my Myki card. To prove this theory I constructed a program using the famous card number generating, 'luhn', algorithm to make a list of all valid myki card numbers to ever exist without the use of any artificial intelligence. This blatant misinformation being fed to Australian consumers by, in this case, shifting the blame away from a public corporations poor security practices onto a widely misunderstood technology, only serves to perpetrate our mistrust of artificial intelligence and skew understanding of the technologies capabilities .
 
Instances of this kind have been reflected in a study published last year from the University of Queensland, who surveyed over 17,000 people around the Australasia region on their understanding of artificial intelligence and its effects. This study has revealed Australians poor education of the technology compared to other countries in the region, with only two in five Australians recognising themselves as having an understanding of AI and its use cases compared the the roughly four in five average of other Australasian countries. This sentiment among Australian consumers has led to little attempt at education of the technology, only further sensationalised depictions of AI throughout popular culture, perpetrating its troubling widespread fear. 

## Disproving Speculation
Many of the public's first exposure to the concept of artificial intelligence has been through its portrayal in science fiction media where it is depicted in a form known as artificial general intelligence or AGI. This AI is capable of comprehending complex concepts and forming independent thoughts, achieving this advancement is widely considered to be the end goal of AI development. Many leaders in the field, such as polarising CEO of Tesla an ex-partner in OpenAI, have been extremely vocal of their predicted timelines to achieve AGI as soon as 2029, citing speculation of artificial intelligence future exponential growth following rapid advancement over the last decade. This speculation has caused a modern gold rush of adopting and investing in the latest AI technologies so to not be left behind.

However recent research and the trends of similar past phenomena have shown with a high degree of certainty that current methods of development cannot achieve AGI, moreover cannot even reasonably sustain its current rate of growth. A renowned phenomenon observed by and named after Intel co-founder, Gordon Moore, stated  'The number of transistors in an integrated circuit, \[or computer chip], will double every year,'  due to a historical trend of transistor size reduction. This was later revised to every two years, from which its projection remained true for many years, however at the height of its speculation in 2005 Moore admitted the trend was not sustainable and failed to recognise physical limitations of production. This would be realised in recent years as development of hardware powering modern AI technology significantly significantly slowed causing an almost plateau in recent advancements. 

The phenomenon of advancement in search of AGI perpetrated through popular culture has further been opposed recently through a renowned research paper published by 'Avixr' into the sustainability of AI growth. The paper concluded that AI's primary means for advancement, training data, will almost certainly limit the abilities of AI within the near future. Analysis conducted revealed that in order to train any speculated AGI five to six orders of magnitude more training data produced by humans would be required to even come near the goal, moreover if our current AI continued to advance at its speculated exponential rate all existing training data would be exhausted by the year 2028. This research and analysis of historical growth sustainability has show the uncertainty and baselessness of these proposed timelines and predictions that are advertised to consumers with the promise of AGI. Furthermore the imagery used of extraordinary Intelligence has only perpetrated hysteria similar to that at the time of early computer chip development, skewing public perception of the technology and its dangers.

## The Real Dangers
Although popular cultures influence In artificial intelligence has led to a widespread misunderstanding of the technology and unrealistic speculation of its dangers it is not without any potential of malicious use to negatively effect the general public. The rise of artificial intelligences dangers to Australian consumers has had a clear steady rise over the past half decade of public availability to powerful models, although commonly sensationalised causing doubt among a flood of misinformation. These malicious uses come from the strengths of AI in its abilities to conduct a single task, such as voice emulation used by scammers to target consumers, essay writing used by students potentially threatening the academic integrity of the school system and even graphic design generation infringing on the copyright of talented artists. 

However there are extreme examples of artificial intelligence been used in harmful ways in our local communities, such as a recent scandal from a Victorian private school, Bacchus Marsh Grammar, where a schoolboy has been arrested after using conveniently available AI tools to generate sexually explicit content of fifty female classmates. This disturbing content was shared around the local community by the schoolboy causing immense distress to victims. This type of deplorable behaviour demonstrates the dangers of artificial intelligence, not as a conscious technology, but as a specialised tool enabling a malicious actor to cause harm on victims.

## Conclusion

